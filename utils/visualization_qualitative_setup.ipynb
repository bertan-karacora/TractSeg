{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup for qualitative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import nibabel as nib\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "import tractseg.config as config\n",
    "import tractseg.libs.data_utils\n",
    "import tractseg.utils.crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT = \"987983\"\n",
    "EXPERIMENTS = [\"peaks\", \"fodfs\", \"rank_3_approx\"]\n",
    "\n",
    "PATH_REL_DATA = \"data/HCP\"\n",
    "PATH_REL_DIFFUSION = \"Diffusion\"\n",
    "PATH_REL_SEGMENTATIONS = \"segmentations\"\n",
    "PATH_REL_REFERENCE = \"bundle_masks\"\n",
    "FILENAME_MASK_CROPPED = \"mask_cropped.nii.gz\"\n",
    "FILENAME_MASK = \"nodif_brain_mask.nii.gz\"\n",
    "FILENAME_REFERENCE = \"bundle_masks.nii.gz\"\n",
    "\n",
    "path_dir_subject = Path(config.PATH_CWD) / PATH_REL_DATA / SUBJECT\n",
    "path_dir_experiments = Path(config.PATH_DIR_EXP)\n",
    "paths_segmentations = [path_dir_experiments / experiment / PATH_REL_SEGMENTATIONS / f\"{SUBJECT}_segmentation.nii.gz\" for experiment in EXPERIMENTS]\n",
    "path_reference = path_dir_subject / PATH_REL_REFERENCE / FILENAME_REFERENCE\n",
    "path_mask_cropped = path_dir_subject / PATH_REL_DIFFUSION / FILENAME_MASK_CROPPED\n",
    "path_mask = path_dir_subject / PATH_REL_DIFFUSION / FILENAME_MASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nrrd(path):\n",
    "    img, header_img = nrrd.read(path)\n",
    "    return img, header_img\n",
    "\n",
    "\n",
    "def load_nifti(path):\n",
    "    img_nifti = nib.load(path)\n",
    "    img = img_nifti.get_fdata()\n",
    "    affine_img = img_nifti.affine\n",
    "    return img, affine_img\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    header_img, affine_img = None, None\n",
    "    if path.suffixes == [\".nrrd\"]:\n",
    "        img, header_img = load_nrrd(path)\n",
    "    elif path.suffixes == [\".nii\", \".gz\"]:\n",
    "        img, affine_img = load_nifti(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported input file type.\")\n",
    "\n",
    "    return img, header_img, affine_img\n",
    "\n",
    "\n",
    "def save_img(path, img, img_header=None, affine=None):\n",
    "    if path.suffixes == [\".nrrd\"]:\n",
    "        nrrd.write(str(path), img, img_header)\n",
    "    elif path.suffixes == [\".nii\", \".gz\"]:\n",
    "        img_output = nib.Nifti1Image(img, affine if affine is not None else np.eye(4))\n",
    "        nib.save(img_output, str(path))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map segmentations back to HCP data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20, 125],\n",
       "       [ 23, 156],\n",
       "       [  9, 112]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask, _, affine = load_img(path_mask)\n",
    "bb = tractseg.utils.crop.bounding_box(mask)\n",
    "\n",
    "display(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 144, 144)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'original_shape': (105, 133, 103),\n",
       " 'pad_x': 14.0,\n",
       " 'pad_y': 0.0,\n",
       " 'pad_z': 15.0,\n",
       " 'zoom': 1.0827067669172932}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_cropped, _, _ = load_img(path_mask_cropped)\n",
    "mask_square, transformation = tractseg.libs.data_utils.pad_and_scale_img_to_square_img(mask_cropped, target_size=144, nr_cpus=1)\n",
    "\n",
    "display(mask_square.shape)\n",
    "display(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference, _, _ = load_img(path_reference)\n",
    "reference = reference.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path_segmentations in paths_segmentations:\n",
    "#     segmentation, _, _ = load_img(path_segmentations)\n",
    "#     segmentation = segmentation.astype(np.int16)\n",
    "#     segmentation = tractseg.libs.data_utils.cut_and_scale_img_back_to_original_img(segmentation, transformation, nr_cpus=1)\n",
    "\n",
    "#     segmentation_rescaled = np.zeros((145, 174, 145, 72), dtype=np.int16)\n",
    "#     segmentation_rescaled[bb[0, 0] : bb[0, 1], bb[1, 0] : bb[1, 1], bb[2, 0] : bb[2, 1], :] = segmentation\n",
    "\n",
    "#     path_segmentations_rescaled = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled.nii.gz\"\n",
    "#     save_img(path_segmentations_rescaled, segmentation_rescaled, affine=affine)\n",
    "\n",
    "#     path_segmentations_rescaled_fp = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fp.nii.gz\"\n",
    "#     save_img(path_segmentations_rescaled_fp, np.clip(segmentation_rescaled - reference, a_min=0, a_max=None), affine=affine)\n",
    "\n",
    "#     path_segmentations_rescaled_fn = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fn.nii.gz\"\n",
    "#     save_img(path_segmentations_rescaled_fn, np.clip(reference - segmentation_rescaled, a_min=0, a_max=None), affine=affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = np.array([25, 15, 4])\n",
    "for path_segmentations in paths_segmentations:\n",
    "    segmentation, _, _ = load_img(path_segmentations)\n",
    "    segmentation = segmentation.astype(np.int16)\n",
    "    segmentation = tractseg.libs.data_utils.cut_and_scale_img_back_to_original_img(segmentation, transformation, nr_cpus=1)\n",
    "\n",
    "    segmentation_rescaled = np.zeros((145, 174, 145, 72), dtype=np.int16)\n",
    "    segmentation_rescaled[bb[0, 0] : bb[0, 1], bb[1, 0] : bb[1, 1], bb[2, 0] : bb[2, 1], :] = segmentation\n",
    "\n",
    "    for tract in tracts:\n",
    "        path_segmentations_rescaled = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_{tract}.nii.gz\"\n",
    "        save_img(path_segmentations_rescaled, segmentation_rescaled[..., tract], affine=affine)\n",
    "\n",
    "        path_segmentations_rescaled_fp = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fp_{tract}.nii.gz\"\n",
    "        save_img(\n",
    "            path_segmentations_rescaled_fp, np.clip(segmentation_rescaled[..., tract] - reference[..., tract], a_min=0, a_max=None), affine=affine\n",
    "        )\n",
    "\n",
    "        path_segmentations_rescaled_fn = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fn_{tract}.nii.gz\"\n",
    "        save_img(\n",
    "            path_segmentations_rescaled_fn, np.clip(reference[..., tract] - segmentation_rescaled[..., tract], a_min=0, a_max=None), affine=affine\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
