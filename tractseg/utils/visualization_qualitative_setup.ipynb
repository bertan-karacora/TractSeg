{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup for qualitative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import nibabel as nib\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "import tractseg.config as config\n",
    "import tractseg.libs.data_utils\n",
    "import tractseg.utils.crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT = \"987983\"\n",
    "EXPERIMENTS = [\"peaks\", \"fodfs\", \"rank_3_approx\"]\n",
    "\n",
    "PATH_REL_DATA = \"data/HCP\"\n",
    "PATH_REL_DIFFUSION = \"Diffusion\"\n",
    "PATH_REL_SEGMENTATIONS = \"segmentations\"\n",
    "PATH_REL_REFERENCE = \"bundle_masks\"\n",
    "FILENAME_MASK_CROPPED = \"mask_cropped.nii.gz\"\n",
    "FILENAME_MASK = \"nodif_brain_mask.nii.gz\"\n",
    "FILENAME_REFERENCE = \"bundle_masks.nii.gz\"\n",
    "\n",
    "path_dir_subject = Path(config.PATH_CWD) / PATH_REL_DATA / SUBJECT\n",
    "path_dir_experiments = Path(config.PATH_DIR_EXP)\n",
    "paths_segmentations = [path_dir_experiments / experiment / PATH_REL_SEGMENTATIONS / f\"{SUBJECT}_segmentation.nii.gz\" for experiment in EXPERIMENTS]\n",
    "path_reference = path_dir_subject / PATH_REL_REFERENCE / FILENAME_REFERENCE\n",
    "path_mask_cropped = path_dir_subject / PATH_REL_DIFFUSION / FILENAME_MASK_CROPPED\n",
    "path_mask = path_dir_subject / PATH_REL_DIFFUSION / FILENAME_MASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nrrd(path):\n",
    "    img, header_img = nrrd.read(path)\n",
    "    return img, header_img\n",
    "\n",
    "\n",
    "def load_nifti(path):\n",
    "    img_nifti = nib.load(path)\n",
    "    img = img_nifti.get_fdata()\n",
    "    affine_img = img_nifti.affine\n",
    "    return img, affine_img\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    header_img, affine_img = None, None\n",
    "    if path.suffixes == [\".nrrd\"]:\n",
    "        img, header_img = load_nrrd(path)\n",
    "    elif path.suffixes == [\".nii\", \".gz\"]:\n",
    "        img, affine_img = load_nifti(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported input file type.\")\n",
    "\n",
    "    return img, header_img, affine_img\n",
    "\n",
    "\n",
    "def save_img(path, img, img_header=None, affine=None):\n",
    "    if path.suffixes == [\".nrrd\"]:\n",
    "        nrrd.write(str(path), img, img_header)\n",
    "    elif path.suffixes == [\".nii\", \".gz\"]:\n",
    "        img_output = nib.Nifti1Image(img, affine if affine is not None else np.eye(4))\n",
    "        nib.save(img_output, str(path))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map segmentations back to HCP data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20, 125],\n",
       "       [ 23, 156],\n",
       "       [  9, 112]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask, _, affine = load_img(path_mask)\n",
    "bb = tractseg.utils.crop.bounding_box(mask)\n",
    "\n",
    "display(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 144, 144)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'original_shape': (105, 133, 103),\n",
       " 'pad_x': 14.0,\n",
       " 'pad_y': 0.0,\n",
       " 'pad_z': 15.0,\n",
       " 'zoom': 1.0827067669172932}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_cropped, _, _ = load_img(path_mask_cropped)\n",
    "mask_square, transformation = tractseg.libs.data_utils.pad_and_scale_img_to_square_img(mask_cropped, target_size=144, nr_cpus=1)\n",
    "\n",
    "display(mask_square.shape)\n",
    "display(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference, _, _ = load_img(path_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 174, 145, 72)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(145, 174, 145, 72)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path_segmentations \u001b[38;5;129;01min\u001b[39;00m paths_segmentations:\n\u001b[1;32m      2\u001b[0m     segmentation, _, _ \u001b[38;5;241m=\u001b[39m load_img(path_segmentations)\n\u001b[0;32m----> 3\u001b[0m     segmentation \u001b[38;5;241m=\u001b[39m \u001b[43mtractseg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcut_and_scale_img_back_to_original_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnr_cpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     segmentation_rescaled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m145\u001b[39m, \u001b[38;5;241m174\u001b[39m, \u001b[38;5;241m145\u001b[39m, \u001b[38;5;241m72\u001b[39m))\n\u001b[1;32m      6\u001b[0m     segmentation_rescaled[bb[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] : bb[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], bb[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m] : bb[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], bb[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m] : bb[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m], :] \u001b[38;5;241m=\u001b[39m segmentation\n",
      "File \u001b[0;32m~/TractSeg/tractseg/libs/data_utils.py:70\u001b[0m, in \u001b[0;36mcut_and_scale_img_back_to_original_img\u001b[0;34m(data, t, nr_cpus)\u001b[0m\n\u001b[1;32m     68\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m ndimage\u001b[38;5;241m.\u001b[39mzoom(data, (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzoom\u001b[39m\u001b[38;5;124m\"\u001b[39m]), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nr_dims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mimg_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_first_three_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzoom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnr_cpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_cpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m x_residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     73\u001b[0m y_residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/TractSeg/tractseg/libs/img_utils.py:230\u001b[0m, in \u001b[0;36mresize_first_three_dims\u001b[0;34m(img, order, zoom, nr_cpus)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ndimage\u001b[38;5;241m.\u001b[39mzoom(img[:, :, :, grad_idx], zoom, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    229\u001b[0m nr_cpus \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;28;01mif\u001b[39;00m nr_cpus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nr_cpus\n\u001b[0;32m--> 230\u001b[0m img_sm \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_cpus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_process_gradient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrad_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(img_sm)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/TractSeg/.venv/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/TractSeg/.venv/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/TractSeg/tractseg/libs/img_utils.py:227\u001b[0m, in \u001b[0;36mresize_first_three_dims.<locals>._process_gradient\u001b[0;34m(grad_idx)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_gradient\u001b[39m(grad_idx):\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TractSeg/.venv/lib/python3.9/site-packages/scipy/ndimage/_interpolation.py:819\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    815\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    816\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    817\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    818\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 819\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for path_segmentations in paths_segmentations:\n",
    "    segmentation, _, _ = load_img(path_segmentations)\n",
    "    segmentation = tractseg.libs.data_utils.cut_and_scale_img_back_to_original_img(segmentation, transformation, nr_cpus=1)\n",
    "\n",
    "    segmentation_rescaled = np.zeros((145, 174, 145, 72))\n",
    "    segmentation_rescaled[bb[0, 0] : bb[0, 1], bb[1, 0] : bb[1, 1], bb[2, 0] : bb[2, 1], :] = segmentation\n",
    "\n",
    "    path_segmentations_rescaled = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled.nii.gz\"\n",
    "    save_img(path_segmentations_rescaled, segmentation_rescaled, affine=affine)\n",
    "\n",
    "    path_segmentations_rescaled_fp = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fp.nii.gz\"\n",
    "    save_img(path_segmentations_rescaled_fp, np.clip(segmentation_rescaled - reference, a_min=0, a_max=None), affine=affine)\n",
    "\n",
    "    path_segmentations_rescaled_fn = path_segmentations.parents[0] / f\"{SUBJECT}_segmentation_rescaled_fn.nii.gz\"\n",
    "    save_img(path_segmentations_rescaled_fn, np.clip(reference - segmentation_rescaled, a_min=0, a_max=None), affine=affine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
